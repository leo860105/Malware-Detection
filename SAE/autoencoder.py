import tensorflow as tf
from util import *


class AutoEncoder:

    def __init__(self, data_path, dim, hidden_dims, epoch=1000, learning_rate=0.005, batch_size=100, print_step=50):
        data = process_train(data_path)
        self.train_batch = generate_batch(data, batch_size)
        self.dim = dim
        self.hidden_dims = hidden_dims
        self.epoch = epoch
        self.learning_rate = learning_rate
        self.print_step = print_step
        self.w_enc = []
        self.b_enc = []

    def encoder(self, data):
        with tf.variable_scope('encoder'):
            w0 = self.w_enc[0]
            b0 = self.b_enc[0]

            h0 = tf.matmul(data, w0) + b0
            h0 = tf.nn.sigmoid(h0, name='encode_activation')

            w1 = self.w_enc[1]
            b1 = self.b_enc[1]

            h1 = tf.matmul(h0, w1) + b1
            h1 = tf.nn.sigmoid(h1, name='encode_activation')

            return h1

    def decoder(self, data):
        with tf.variable_scope('decoder'):
            w_init = tf.contrib.layers.variance_scaling_initializer()
            b_init = tf.constant_initializer(0.)

            w0 = tf.get_variable('w0_dec', [self.hidden_dims[1], self.hidden_dims[0]], initializer=w_init)
            b0 = tf.get_variable('b0_dec', [self.hidden_dims[0]], initializer=b_init)

            h0 = tf.matmul(data, w0) + b0
            h0 = tf.nn.sigmoid(h0, name='decode_activation')

            w1 = tf.get_variable('w1_dec', [self.hidden_dims[0], self.dim], initializer=w_init)
            b1 = tf.get_variable('b1_dec', [self.dim], initializer=b_init)

            h1 = tf.matmul(h0, w1) + b1
            h1 = tf.nn.sigmoid(h1, name='decode_activation')

            return h1

    def train(self):
        w_init = tf.contrib.layers.variance_scaling_initializer()
        b_init = tf.constant_initializer(0.)

        self.w_enc = [tf.get_variable('w0_enc', [self.dim, self.hidden_dims[0]], initializer=w_init),
                      tf.get_variable('w1_enc', [self.hidden_dims[0], self.hidden_dims[1]], initializer=w_init)]
        self.b_enc = [tf.get_variable('b0_enc', [self.hidden_dims[0]], initializer=b_init),
                      tf.get_variable('b1_enc', [self.hidden_dims[1]], initializer=b_init)]

        x = tf.placeholder(tf.float32)

        encoded = self.encoder(x)
        decoded = self.decoder(encoded)

        loss = tf.losses.mean_squared_error(x, decoded)
        train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(loss)

        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())

            for i in range(self.epoch):
                count = 0
                for batch in self.train_batch:
                    count += 1
                    _, l = sess.run([train_op, loss], feed_dict={x: batch})
                    print('Epoch: %i: Step %i, Minibatch Loss: %f' % (i, count, l))
